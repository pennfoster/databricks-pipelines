name: PR - Release Code to Production

on:
  pull_request:
    types: closed
    branches: [main, master]

jobs:
  pull_latest_commit:
    if: github.event.pull_request.merged == true
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Update Production Repo
        run: |
          curl -L -X PATCH '${{vars.DATABRICKS_HOST}}/api/2.0/repos/${{vars.DATABRICKS_REPO_ID}}' \
            -H 'Authorization: Bearer ${{secrets.DATABRICKS_TOKEN}}' \
            -H 'Content-Type: application/json' \
            -d '{"branch": "${{ github.base_ref }}"}'
  
  update_jobs:
    needs: pull_latest_commit
    runs-on: ubuntu-latest
    environment: production
    env:
      DATABRICKS_HOST: ${{vars.DATABRICKS_HOST}}
      DATABRICKS_TOKEN: ${{secrets.DATABRICKS_TOKEN}}
    steps:
    # Documentation for Databricks specific actions found @ https://github.com/databricks/run-notebook/blob/main/action.yml    
      - name: Update jobs
        id: update_jobs
        uses: databricks/run-notebook@v0
        with:
          workspace-notebook-path: /Repos/ETL/databricks_pipelines/notebooks/ci_cd/update_env_jobs
          libraries-json: >
            [
              {"pypi": {"package": "aiohttp"}},
              {"pypi": {"package": "pendulum"}}
            ]
          notebook-params-json: >
            [
              {"key": "jobs_branch", "value": "${{ github.base_ref }}"}
            ]
          new-cluster-json: >
            {
              "num_workers": 1,
              "spark_version": "11.3.x-scala2.12",
              "node_type_id": "Standard_F4"
            }
          access-control-list-json: >
            [
              {
                "group_name": "users",
                "permission_level": "CAN_VIEW"
              }
            ]